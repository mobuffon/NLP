{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11100 entries, 0 to 11099\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Text      11100 non-null  object\n",
      " 1   CB_Label  11100 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 173.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Coding CBS/NLP/MA 2/CyberBullying Comments Dataset.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5550.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        5550.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.CB_Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data is evenly distributed and does not have any null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/moritzvonbuchwaldt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/moritzvonbuchwaldt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/moritzvonbuchwaldt/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     damn someone nana beach one dont think ic stea...\n",
       "1     kidding dick clark corpse mechanically operate...\n",
       "2     read article jobros thought damn cash jobro po...\n",
       "3     got one fucking day sprinkle back sunshine dou...\n",
       "4     already listening elliott smith fucking hate k...\n",
       "5                  told derek go fuck devyn told u calm\n",
       "6                  watching new smosh video laughing as\n",
       "7     mom like catholicism idea sinner birth irked l...\n",
       "8     ya know lol big thunder mountain broke got rid...\n",
       "9                                           lucky bitch\n",
       "10    hate auto dm better way show actually care fol...\n",
       "11    top notch click dont hate hater u mad cuz u br...\n",
       "12                question fuck father mia like two day\n",
       "13    fair enough get as around sometime later voice...\n",
       "14    yeah seems like got bitch somewhere could brai...\n",
       "Name: cleaned_text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1.1)\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download the required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize the lemmatizer and stopwords list\n",
    "lem = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def data_preprocess(text):\n",
    "    # Tokenize text\n",
    "    wtokens = word_tokenize(text)\n",
    "\n",
    "   # Filtering tokens\n",
    "    t_filtered = []\n",
    "    for t in wtokens:\n",
    "        # Convert token to lowercase and check if it's not in stopwords and is alphabetic\n",
    "        if t.lower() not in stop_words and t.isalpha():\n",
    "        # Add the lowercase token to filtered_tokens\n",
    "            t_filtered.append(t.lower())\n",
    "\n",
    "# Lemmatization\n",
    "    t_lemmatized = []\n",
    "    for t in t_filtered:\n",
    "    # Lemmatize token\n",
    "        lemma_t = lem.lemmatize(t)\n",
    "    # Add lemmatized token to lemmatized_tokens\n",
    "        t_lemmatized.append(lemma_t)\n",
    "\n",
    "    # Rejoin the processed tokens into a single string\n",
    "    return \" \".join(t_lemmatized) \n",
    "\n",
    "# (1.2)\n",
    "df['cleaned_text'] = df['Text'].apply(data_preprocess)\n",
    "df['cleaned_text'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "#vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df.cleaned_text)\n",
    "y = df.CB_Label\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y , test_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB()\n",
      "GaussianNB()\n",
      "MultinomialNB()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Model</th>\n",
       "            <th>F1 Score</th>\n",
       "            <th>Accuracy</th>\n",
       "            <th>Precision</th>\n",
       "            <th>Recall</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>BernoulliNB()</td>\n",
       "            <td>0.6869054152495433</td>\n",
       "            <td>0.6872747747747747</td>\n",
       "            <td>0.6938726663475348</td>\n",
       "            <td>0.6593131680691381</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>GaussianNB()</td>\n",
       "            <td>0.5836851435949382</td>\n",
       "            <td>0.5896396396396396</td>\n",
       "            <td>0.6100555393159894</td>\n",
       "            <td>0.47464180122811006</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>MultinomialNB()</td>\n",
       "            <td>0.6682143922069068</td>\n",
       "            <td>0.6699324324324324</td>\n",
       "            <td>0.6431081608746584</td>\n",
       "            <td>0.7491471457812144</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------------+--------------------+--------------------+--------------------+---------------------+\n",
       "|      Model      |      F1 Score      |      Accuracy      |     Precision      |        Recall       |\n",
       "+-----------------+--------------------+--------------------+--------------------+---------------------+\n",
       "|  BernoulliNB()  | 0.6869054152495433 | 0.6872747747747747 | 0.6938726663475348 |  0.6593131680691381 |\n",
       "|   GaussianNB()  | 0.5836851435949382 | 0.5896396396396396 | 0.6100555393159894 | 0.47464180122811006 |\n",
       "| MultinomialNB() | 0.6682143922069068 | 0.6699324324324324 | 0.6431081608746584 |  0.7491471457812144 |\n",
       "+-----------------+--------------------+--------------------+--------------------+---------------------+"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn import metrics\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "models = [BernoulliNB(), GaussianNB(), MultinomialNB()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"F1 Score\", \"Accuracy\", \"Precision\", \"Recall\"]\n",
    "\n",
    "for m in models:\n",
    "    print(m)\n",
    "    model = m.fit(Xtrain.toarray(),ytrain)\n",
    "    \n",
    "    pred = model.predict(Xtest.toarray())   \n",
    "    table.add_row([m, metrics.f1_score(ytest, pred, average='macro'), metrics.accuracy_score(ytest, pred), metrics.precision_score(ytest, pred), metrics.recall_score(ytest, pred)])\n",
    "table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we want to minimize the texts with bullying that we miss so Recall is the correct metric to look at. As it shows how many of all Bullying messages classify correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "F1 Score 0.6778236159500048\n",
      "Accuracy 0.6781531531531532\n",
      "Recall 0.7170798271548783\n",
      "Precision 0.6614222781623663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "print(model)\n",
    "model = model.fit(Xtrain.toarray(),ytrain)\n",
    "pred = model.predict(Xtest)\n",
    "print(\"F1 Score\",metrics.f1_score(ytest, pred, average='macro'))\n",
    "print(\"Accuracy\",metrics.accuracy_score(ytest, pred))\n",
    "print(\"Recall\",metrics.recall_score(ytest, pred))\n",
    "print(\"Precision\",metrics.precision_score(ytest, pred))\n",
    "\n",
    "table.add_row([model, metrics.f1_score(ytest, pred, average='macro'), metrics.accuracy_score(ytest, pred), metrics.precision_score(ytest, pred), metrics.recall_score(ytest, pred)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Recall Score: 0.6902482153483562\n",
      "Best Parameters: {'clf__C': 1, 'clf__penalty': 'l2', 'clf__solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Define hyperparameters to search\n",
    "param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10],\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__solver': ['liblinear']  # 'liblinear' works well with small datasets & L1/L2\n",
    "}\n",
    "\n",
    "# Set up grid search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', verbose=1)\n",
    "\n",
    "# Run search\n",
    "grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "# Best result\n",
    "print(\"Best Recall Score:\", grid_search.best_score_)\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same parameters as default ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.2, solver='liblinear')\n",
      "F1 Score 0.6564364296875254\n",
      "Accuracy 0.6608108108108108\n",
      "Recall 0.7812144644075506\n",
      "Precision 0.626253418413856\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LogisticRegression(C = 0.2, solver=\"liblinear\")\n",
    "print(model)\n",
    "model = model.fit(Xtrain.toarray(),ytrain)\n",
    "pred = model.predict(Xtest)\n",
    "print(\"F1 Score\",metrics.f1_score(ytest, pred, average='macro'))\n",
    "print(\"Accuracy\",metrics.accuracy_score(ytest, pred))\n",
    "print(\"Recall\",metrics.recall_score(ytest, pred))\n",
    "print(\"Precision\",metrics.precision_score(ytest, pred))\n",
    "table.add_row([model, metrics.f1_score(ytest, pred, average='macro'), metrics.accuracy_score(ytest, pred), metrics.precision_score(ytest, pred), metrics.recall_score(ytest, pred)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Model</th>\n",
       "            <th>F1 Score</th>\n",
       "            <th>Accuracy</th>\n",
       "            <th>Precision</th>\n",
       "            <th>Recall</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>BernoulliNB()</td>\n",
       "            <td>0.6869054152495433</td>\n",
       "            <td>0.6872747747747747</td>\n",
       "            <td>0.6938726663475348</td>\n",
       "            <td>0.6593131680691381</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>GaussianNB()</td>\n",
       "            <td>0.5836851435949382</td>\n",
       "            <td>0.5896396396396396</td>\n",
       "            <td>0.6100555393159894</td>\n",
       "            <td>0.47464180122811006</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>MultinomialNB()</td>\n",
       "            <td>0.6682143922069068</td>\n",
       "            <td>0.6699324324324324</td>\n",
       "            <td>0.6431081608746584</td>\n",
       "            <td>0.7491471457812144</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>LogisticRegression()</td>\n",
       "            <td>0.6778236159500048</td>\n",
       "            <td>0.6781531531531532</td>\n",
       "            <td>0.6614222781623663</td>\n",
       "            <td>0.7170798271548783</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>LogisticRegression(C=0.2, solver=&#x27;liblinear&#x27;)</td>\n",
       "            <td>0.6564364296875254</td>\n",
       "            <td>0.6608108108108108</td>\n",
       "            <td>0.626253418413856</td>\n",
       "            <td>0.7812144644075506</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------------------------------------------+--------------------+--------------------+--------------------+---------------------+\n",
       "|                     Model                     |      F1 Score      |      Accuracy      |     Precision      |        Recall       |\n",
       "+-----------------------------------------------+--------------------+--------------------+--------------------+---------------------+\n",
       "|                 BernoulliNB()                 | 0.6869054152495433 | 0.6872747747747747 | 0.6938726663475348 |  0.6593131680691381 |\n",
       "|                  GaussianNB()                 | 0.5836851435949382 | 0.5896396396396396 | 0.6100555393159894 | 0.47464180122811006 |\n",
       "|                MultinomialNB()                | 0.6682143922069068 | 0.6699324324324324 | 0.6431081608746584 |  0.7491471457812144 |\n",
       "|              LogisticRegression()             | 0.6778236159500048 | 0.6781531531531532 | 0.6614222781623663 |  0.7170798271548783 |\n",
       "| LogisticRegression(C=0.2, solver='liblinear') | 0.6564364296875254 | 0.6608108108108108 | 0.626253418413856  |  0.7812144644075506 |\n",
       "+-----------------------------------------------+--------------------+--------------------+--------------------+---------------------+"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
