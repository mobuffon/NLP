{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8127be7e",
      "metadata": {
        "id": "8127be7e"
      },
      "source": [
        "# <font color='white'> Lab-06 (Solution) <font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "627034c8",
      "metadata": {
        "id": "627034c8"
      },
      "source": [
        "### <font color='white'> Data Preparation <font>\n",
        "    \n",
        "Download Emotios dataset from Kaggle https://www.kaggle.com/datasets/nelgiriyewithana/emotions\n",
        "    \n",
        "Use Pandas to load the dataset and display the first fifteen rows of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "df39aece",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "df39aece",
        "outputId": "424e0d8f-58f3-40fe-acae-3a180c116ccc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>i just feel really helpless and heavy hearted</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>i gave up my internship with the dmrg and am f...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>i dont know i feel so lost</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>i was beginning to feel quite disheartened</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>i would think that whomever would be lucky eno...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>i fear that they won t ever feel that deliciou...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>im forever taking some time out to have a lie ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>i can still lose the weight without feeling de...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>i try to be nice though so if you get a bitchy...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>im feeling a little like a damaged tree and th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>i have officially graduated im not feeling as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>i feel like a jerk because the library student...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>i feel my portfolio demonstrates how eager i a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0                                               text  label\n",
              "0            0      i just feel really helpless and heavy hearted      4\n",
              "1            1  ive enjoyed being able to slouch about relax a...      0\n",
              "2            2  i gave up my internship with the dmrg and am f...      4\n",
              "3            3                         i dont know i feel so lost      0\n",
              "4            4  i am a kindergarten teacher and i am thoroughl...      4\n",
              "5            5         i was beginning to feel quite disheartened      0\n",
              "6            6  i would think that whomever would be lucky eno...      2\n",
              "7            7  i fear that they won t ever feel that deliciou...      1\n",
              "8            8  im forever taking some time out to have a lie ...      5\n",
              "9            9  i can still lose the weight without feeling de...      0\n",
              "10          10  i try to be nice though so if you get a bitchy...      1\n",
              "11          11  im feeling a little like a damaged tree and th...      0\n",
              "12          12  i have officially graduated im not feeling as ...      1\n",
              "13          13  i feel like a jerk because the library student...      3\n",
              "14          14  i feel my portfolio demonstrates how eager i a...      1"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# (0.1)\n",
        "import pandas as pd\n",
        "df = pd.read_csv('/Users/johannuchelwildt/.cache/kagglehub/datasets/nelgiriyewithana/emotions/versions/1/text.csv')\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b1b8141",
      "metadata": {
        "id": "1b1b8141"
      },
      "source": [
        "### <font color='white'> Problem 1: Data Pre-processing <font>\n",
        "    \n",
        "   \n",
        "(1.1) Write a function, data_preprocess, to tokenize text, remove stopwords and non-alphabetic tokens, apply lemmatization, and rejoin tokens into a single string.\n",
        "    \n",
        "(1.2) Load the dataset and apply the data_preprocess function to pre-process the text data. Preview the data to ensure pre-processing is as expected.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1b377ea3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b377ea3",
        "outputId": "0d9726af-edd2-424c-8d09-996ad6c0efef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/johannuchelwildt/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/johannuchelwildt/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/johannuchelwildt/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0                    feel really helpless heavy hearted\n",
              "1     ive enjoyed able slouch relax unwind frankly n...\n",
              "2               gave internship dmrg feeling distraught\n",
              "3                                   dont know feel lost\n",
              "4     kindergarten teacher thoroughly weary job take...\n",
              "5                     beginning feel quite disheartened\n",
              "6     would think whomever would lucky enough stay s...\n",
              "7     fear ever feel delicious excitement christmas ...\n",
              "8                 im forever taking time lie feel weird\n",
              "9            still lose weight without feeling deprived\n",
              "10    try nice though get bitchy person phone window...\n",
              "11    im feeling little like damaged tree root littl...\n",
              "12    officially graduated im feeling ecstatic thoug...\n",
              "13    feel like jerk library student claim love scra...\n",
              "14    feel portfolio demonstrates eager learn know b...\n",
              "Name: cleaned_text, dtype: object"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# (1.1)\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download the required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize the lemmatizer and stopwords list\n",
        "lem = WordNetLemmatizer()\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "def data_preprocess(text):\n",
        "    # Tokenize text\n",
        "    wtokens = word_tokenize(text)\n",
        "\n",
        "   # Filtering tokens\n",
        "    t_filtered = []\n",
        "    for t in wtokens:\n",
        "        # Convert token to lowercase and check if it's not in stopwords and is alphabetic\n",
        "        if t.lower() not in stop_words and t.isalpha():\n",
        "        # Add the lowercase token to filtered_tokens\n",
        "            t_filtered.append(t.lower())\n",
        "\n",
        "# Lemmatization\n",
        "    t_lemmatized = []\n",
        "    for t in t_filtered:\n",
        "    # Lemmatize token\n",
        "        lemma_t = lem.lemmatize(t)\n",
        "    # Add lemmatized token to lemmatized_tokens\n",
        "        t_lemmatized.append(lemma_t)\n",
        "\n",
        "    # Rejoin the processed tokens into a single string\n",
        "    return \" \".join(t_lemmatized) \n",
        "\n",
        "# (1.2)\n",
        "df['cleaned_text'] = df['text'].apply(data_preprocess)\n",
        "df['cleaned_text'].head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee2d1e69",
      "metadata": {
        "id": "ee2d1e69"
      },
      "source": [
        "### <font color='white'> Problem 2:  Sentiment analysis with TextBlob <font>\n",
        "\n",
        "Use TextBlob to perform sentiment analysis on a sample of texts from the dataset.\n",
        "    \n",
        "Calculate the sentiment polarity and subjectivity of random 5 texts from the dataset and determine if each text is positive, negative, or neutral based on the polarity score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "17b7d0b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17b7d0b1",
        "outputId": "6eb666a5-82b8-449b-b52d-210c0576bd22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1) feel like im letting friend oddly loyal reader extent letting keeping commitment\n",
            "Sentiment polarity: 0.33\n",
            "Sentiment subjectivity: 0.83\n",
            "\n",
            "(2) dey feel oo dey feel lady wan na ping pong matter say matter way whine waist pretty omoge omoge maa lo le oo\n",
            "Sentiment polarity: 0.02\n",
            "Sentiment subjectivity: 0.57\n",
            "\n",
            "(3) celebrated u honest im feeling little nostalgic right\n",
            "Sentiment polarity: 0.11\n",
            "Sentiment subjectivity: 0.74\n",
            "\n",
            "(4) ling u second feeling fuckin glad literally outmatched next team sam carmen dunnowholol\n",
            "Sentiment polarity: 0.17\n",
            "Sentiment subjectivity: 0.33\n",
            "\n",
            "(5) want much possible leaf behind everything said going relating feel irritable everything\n",
            "Sentiment polarity: -0.2\n",
            "Sentiment subjectivity: 0.85\n",
            "\n",
            "(6) feel real forever alone\n",
            "Sentiment polarity: 0.2\n",
            "Sentiment subjectivity: 0.3\n",
            "\n",
            "(7) dressed one little bit feeling creative\n",
            "Sentiment polarity: 0.16\n",
            "Sentiment subjectivity: 0.75\n",
            "\n",
            "(8) im actually feeling little mellow quite melancholy\n",
            "Sentiment polarity: -0.09\n",
            "Sentiment subjectivity: 0.3\n",
            "\n",
            "(9) look feel lovely still feel hungry eating full\n",
            "Sentiment polarity: 0.42\n",
            "Sentiment subjectivity: 0.65\n",
            "\n",
            "(10) glad suffer sense like feel compassionate something even suffering\n",
            "Sentiment polarity: 0.5\n",
            "Sentiment subjectivity: 1.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "random_text = df['cleaned_text'].sample(10).values\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "for i, text in enumerate(random_text,start=1):\n",
        "    tb = TextBlob(text)\n",
        "    score = tb.sentiment.polarity\n",
        "    subj = tb.sentiment.subjectivity\n",
        "    print(f\"({i}) {text}\\nSentiment polarity: {round(score,2)}\\nSentiment subjectivity: {round(subj,2)}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5580672b",
      "metadata": {
        "id": "5580672b"
      },
      "source": [
        "### <font color='white'> Problem 3:  Sentiment analysis with VADER <font>\n",
        "    \n",
        "Analyze the sentiment of same 5 random texts using VADER.\n",
        "    \n",
        "Discuss how VADER’s scores (positive, negative, neutral, compound) provide a nuanced view of sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fy6beaeeW2TV",
      "metadata": {
        "id": "fy6beaeeW2TV"
      },
      "outputs": [],
      "source": [
        "#!pip install vader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dd5dc4cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd5dc4cc",
        "outputId": "f92b7305-1dd9-42b9-9a06-c95c3b62ae29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1) feel like im letting friend oddly loyal reader extent letting keeping commitment\n",
            "VADER Scores: {'neg': 0.0, 'neu': 0.412, 'pos': 0.588, 'compound': 0.886}\n",
            "\n",
            "(2) dey feel oo dey feel lady wan na ping pong matter say matter way whine waist pretty omoge omoge maa lo le oo\n",
            "VADER Scores: {'neg': 0.093, 'neu': 0.706, 'pos': 0.201, 'compound': 0.2263}\n",
            "\n",
            "(3) celebrated u honest im feeling little nostalgic right\n",
            "VADER Scores: {'neg': 0.0, 'neu': 0.32, 'pos': 0.68, 'compound': 0.8176}\n",
            "\n",
            "(4) ling u second feeling fuckin glad literally outmatched next team sam carmen dunnowholol\n",
            "VADER Scores: {'neg': 0.0, 'neu': 0.69, 'pos': 0.31, 'compound': 0.5423}\n",
            "\n",
            "(5) want much possible leaf behind everything said going relating feel irritable everything\n",
            "VADER Scores: {'neg': 0.215, 'neu': 0.694, 'pos': 0.09, 'compound': -0.4215}\n",
            "\n",
            "(6) feel real forever alone\n",
            "VADER Scores: {'neg': 0.4, 'neu': 0.6, 'pos': 0.0, 'compound': -0.25}\n",
            "\n",
            "(7) dressed one little bit feeling creative\n",
            "VADER Scores: {'neg': 0.0, 'neu': 0.509, 'pos': 0.491, 'compound': 0.4325}\n",
            "\n",
            "(8) im actually feeling little mellow quite melancholy\n",
            "VADER Scores: {'neg': 0.311, 'neu': 0.53, 'pos': 0.159, 'compound': -0.3462}\n",
            "\n",
            "(9) look feel lovely still feel hungry eating full\n",
            "VADER Scores: {'neg': 0.0, 'neu': 0.648, 'pos': 0.352, 'compound': 0.5859}\n",
            "\n",
            "(10) glad suffer sense like feel compassionate something even suffering\n",
            "VADER Scores: {'neg': 0.342, 'neu': 0.207, 'pos': 0.451, 'compound': 0.2732}\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/johannuchelwildt/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vdr = SentimentIntensityAnalyzer()\n",
        "\n",
        "for i, text in enumerate(random_text,start=1):\n",
        "    vsa = vdr.polarity_scores(text)\n",
        "    print(f\"({i}) {text}\\nVADER Scores: {vsa}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa3bbd1",
      "metadata": {
        "id": "5aa3bbd1"
      },
      "source": [
        "### <font color='white'> Problem 4:  Sentiment analysis Using AFINN <font>\n",
        "        \n",
        "(4.1) Install the 'afinn' module.\n",
        "    \n",
        "(4.2) Use the AFINN library to calculate sentiment scores for the same 5 random texts.\n",
        "    \n",
        "(4.3) Compare the scores against those obtained from TextBlob and VADER."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "334e8db5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "334e8db5",
        "outputId": "a7b705c4-9688-4c0e-a9c5-79649db975c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1) feel like im letting friend oddly loyal reader extent letting keeping commitment\n",
            "AFINN Score: 8.0\n",
            "\n",
            "(2) dey feel oo dey feel lady wan na ping pong matter say matter way whine waist pretty omoge omoge maa lo le oo\n",
            "AFINN Score: 3.0\n",
            "\n",
            "(3) celebrated u honest im feeling little nostalgic right\n",
            "AFINN Score: 6.0\n",
            "\n",
            "(4) ling u second feeling fuckin glad literally outmatched next team sam carmen dunnowholol\n",
            "AFINN Score: 0.0\n",
            "\n",
            "(5) want much possible leaf behind everything said going relating feel irritable everything\n",
            "AFINN Score: 1.0\n",
            "\n",
            "(6) feel real forever alone\n",
            "AFINN Score: -2.0\n",
            "\n",
            "(7) dressed one little bit feeling creative\n",
            "AFINN Score: 3.0\n",
            "\n",
            "(8) im actually feeling little mellow quite melancholy\n",
            "AFINN Score: -1.0\n",
            "\n",
            "(9) look feel lovely still feel hungry eating full\n",
            "AFINN Score: 3.0\n",
            "\n",
            "(10) glad suffer sense like feel compassionate something even suffering\n",
            "AFINN Score: 3.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# (3.1)\n",
        "# !pip install afinn\n",
        "\n",
        "# (3.2)\n",
        "from afinn import Afinn\n",
        "afinn = Afinn()\n",
        "\n",
        "for i,text in enumerate(random_text,start=1):\n",
        "    score = afinn.score(text)\n",
        "    print(f\"({i}) {text}\\nAFINN Score: {score}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a58aa10",
      "metadata": {
        "id": "2a58aa10"
      },
      "source": [
        "### <font color='white'> Problem 5:  Build a Simple Classifier for Sentiment Analysis with scikit-learn <font>\n",
        "\n",
        "(5.1) Preprocess the dataset to create a binary sentiment label (positive or negative) based on TextBlob’s sentiment polarity.\n",
        "    \n",
        "(5.2) Split the dataset into training and testing sets.\n",
        "    \n",
        "(5.3) Convert the text data into numeric data by using TF-IDF.\n",
        "\n",
        "(5.4) Train a Logistic Regression model and evaluate its performance on the test set. Print the classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3be5f2c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3be5f2c3",
        "outputId": "2c41799c-0316-4f03-f5a9-6c0ebd517dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.90      0.94      0.92     54176\n",
            "    positive       0.94      0.89      0.91     50027\n",
            "\n",
            "    accuracy                           0.92    104203\n",
            "   macro avg       0.92      0.91      0.92    104203\n",
            "weighted avg       0.92      0.92      0.92    104203\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# (5.1) Creating a binary sentiment label based on TextBlob's sentiment polarity\n",
        "df['sentiment_label'] = df['text'].apply(lambda x: 'positive' if TextBlob(x).sentiment.polarity > 0 else 'negative')\n",
        "    \n",
        "# (5.2)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['sentiment_label'], test_size=0.25, random_state=0)\n",
        "\n",
        "#(5.3)\n",
        "num = TfidfVectorizer()\n",
        "X_train_tfidf = num.fit_transform(X_train)\n",
        "X_test_tfidf = num.transform(X_test)\n",
        "# Explanation for why we only transform 2nd time:\n",
        "'''\n",
        "    The TF-IDF vectorizer must only be trained on X_train using .fit_transform().  \n",
        "    Then, for X_test, we apply the same transformation using .transform().  \n",
        "    Using .fit_transform(X_test) instead would relearn the vocabulary on test data, causing data leakage and leading to incorrect model evaluation.\n",
        "'''\n",
        "\n",
        "lrm = LogisticRegression(max_iter=1000)\n",
        "lrm.fit(X_train_tfidf, y_train)\n",
        "y_predicted = lrm.predict(X_test_tfidf)\n",
        "\n",
        "#(5.4)\n",
        "\n",
        "print(classification_report(y_test, y_predicted))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49b16703",
      "metadata": {
        "id": "49b16703"
      },
      "source": [
        "### <font color='white'> Bonus Problem (Optional): Sentiment Analysis using SentiWordNet <font>\n",
        "\n",
        "Use SentiWordNet to calculate sentiment scores for each text entry.\n",
        "    \n",
        "Assign a sentiment category based on the scores.\n",
        "    \n",
        "Display the first 15 entries to see the sentiment scores.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3ff2b6e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "3ff2b6e5",
        "outputId": "3057d6c0-f260-4f64-97f2-2c389d3cfb85"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/johannuchelwildt/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package sentiwordnet to\n",
            "[nltk_data]     /Users/johannuchelwildt/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i just feel really helpless and heavy hearted</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
              "      <td>1.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i gave up my internship with the dmrg and am f...</td>\n",
              "      <td>-0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i dont know i feel so lost</td>\n",
              "      <td>-0.375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
              "      <td>1.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i was beginning to feel quite disheartened</td>\n",
              "      <td>-0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>i would think that whomever would be lucky eno...</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>i fear that they won t ever feel that deliciou...</td>\n",
              "      <td>-0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>im forever taking some time out to have a lie ...</td>\n",
              "      <td>-0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>i can still lose the weight without feeling de...</td>\n",
              "      <td>-1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>i try to be nice though so if you get a bitchy...</td>\n",
              "      <td>0.625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>im feeling a little like a damaged tree and th...</td>\n",
              "      <td>-1.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>i have officially graduated im not feeling as ...</td>\n",
              "      <td>-0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>i feel like a jerk because the library student...</td>\n",
              "      <td>0.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>i feel my portfolio demonstrates how eager i a...</td>\n",
              "      <td>1.125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 text  sentiment_score\n",
              "0       i just feel really helpless and heavy hearted            0.250\n",
              "1   ive enjoyed being able to slouch about relax a...            1.500\n",
              "2   i gave up my internship with the dmrg and am f...           -0.125\n",
              "3                          i dont know i feel so lost           -0.375\n",
              "4   i am a kindergarten teacher and i am thoroughl...            1.250\n",
              "5          i was beginning to feel quite disheartened           -0.500\n",
              "6   i would think that whomever would be lucky eno...            0.500\n",
              "7   i fear that they won t ever feel that deliciou...           -0.250\n",
              "8   im forever taking some time out to have a lie ...           -0.250\n",
              "9   i can still lose the weight without feeling de...           -1.000\n",
              "10  i try to be nice though so if you get a bitchy...            0.625\n",
              "11  im feeling a little like a damaged tree and th...           -1.500\n",
              "12  i have officially graduated im not feeling as ...           -0.250\n",
              "13  i feel like a jerk because the library student...            0.250\n",
              "14  i feel my portfolio demonstrates how eager i a...            1.125"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import sentiwordnet as swn, wordnet\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Download\n",
        "nltk.download('averaged_perceptron_tagger') # For part-of-speech tagging\n",
        "nltk.download('sentiwordnet') #For accessing SentiWordNet\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    \"\"\"Converts part-of-speech tags from the Penn Treebank tag to a WordNet tag.\"\"\"\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        # As default case, return NOUN\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def sentiment_analysis(text):\n",
        "    \"\"\"Performs sentiment analysis using SentiWordNet.\"\"\"\n",
        "    # Preprocess the text and obtain lemmatized tokens\n",
        "    mytokens = word_tokenize(data_preprocess(text)) # use word_tokenize as data_preprocess() returns the joined string\n",
        "\n",
        "# POS tagging on the lemmatized tokens\n",
        "    pos_tagging = pos_tag(mytokens)\n",
        "\n",
        "    pos_score = 0\n",
        "    neg_score = 0\n",
        "\n",
        "    # For each word and tag in pos_tagging, get the sentiment score\n",
        "    for w, t in pos_tagging:\n",
        "        wn_tag = get_wordnet_pos(t)\n",
        "        synsets = list(swn.senti_synsets(w, pos=wn_tag))\n",
        "\n",
        "        # If there are no synsets, skip the word\n",
        "        if not synsets:\n",
        "            continue\n",
        "\n",
        "        # Take the first synset\n",
        "        synset = synsets[0]\n",
        "        pos_score += synset.pos_score()\n",
        "        neg_score += synset.neg_score()\n",
        "\n",
        "    # Compute the overall score\n",
        "    score = pos_score - neg_score\n",
        "    return score\n",
        "\n",
        "df['sentiment_score'] = df['text'].apply(sentiment_analysis)\n",
        "\n",
        "# Display the first 15 entries to see the sentiment scores\n",
        "df[['text', 'sentiment_score']].head(15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423171fb",
      "metadata": {
        "id": "423171fb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
